{"cells":[{"cell_type":"markdown","metadata":{"id":"n4vuKQdq-Pnk"},"source":["creating a bunch of messages, mapping them to a group of appropriate responses. Training data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQ14ActJ9YAo"},"outputs":[],"source":["!gdown --id 1RBF7GFW0CagV4U_N0e4sguAwFBKHoBdl"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KHLAstyAFtPl"},"outputs":[],"source":["import json\n","with open('intents.json', 'r') as f:\n","    intents = json.load(f)\n","\n","print(intents)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XZG_KOS_-HNV"},"outputs":[],"source":["import numpy as np\n","import nltk\n","nltk.download('punkt')\n","from nltk.stem.porter import PorterStemmer\n","stemmer = PorterStemmer()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wHRv4hy4FdDo"},"outputs":[],"source":["def tokenize(sentence):\n","    return nltk.word_tokenize(sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sVwilrxJGINc"},"outputs":[],"source":["def stem(word):\n","    return stemmer.stem(word.lower())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xmx996EQI-lV"},"outputs":[],"source":["def bag_of_words(tokenized_sentence, words):\n","    \n","    # stem each word\n","    sentence_words = [stem(word) for word in tokenized_sentence]\n","    # initialize bag with 0 for each word\n","    bag = np.zeros(len(words), dtype=np.float32)\n","    for idx, w in enumerate(words):\n","        if w in sentence_words: \n","            bag[idx] = 1\n","\n","    return bag"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5vewJn81GTRN"},"outputs":[],"source":["all_words = []\n","tags = []\n","xy = []   # loop through each sentence in our intents patterns\n","for intent in intents['intents']:\n","    tag = intent['tag']\n","    # add to tag list\n","    tags.append(tag)\n","    for pattern in intent['patterns']:  # tokenize each word in the sentence\n","        w = tokenize(pattern)           # add to our words list\n","        all_words.extend(w)             # add to xy pair\n","        xy.append((w, tag))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GUyjSZQgG-UU"},"outputs":[],"source":["ignore_words = ['?', '.', '!']          # stem and lower each word\n","all_words = [stem(w) for w in all_words if w not in ignore_words]         # remove duplicates and sort\n","all_words = sorted(set(all_words))\n","tags = sorted(set(tags))     #unique labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A7NL_t3XHF61"},"outputs":[],"source":["print(len(xy), \"patterns\")\n","print(len(tags), \"tags:\", tags)\n","print(len(all_words), \"unique stemmed words:\", all_words)"]},{"cell_type":"markdown","metadata":{"id":"Ro3otz7HIUhw"},"source":["TRAINING DATA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lDV2PFSRHWT6"},"outputs":[],"source":["X_train = []\n","y_train = []\n","for (pattern_sentence, tag) in xy:\n","    bag = bag_of_words(pattern_sentence, all_words)\n","    X_train.append(bag)\n","    # y: PyTorch CrossEntropyLoss needs only class labels, not one-hot\n","    label = tags.index(tag)\n","    y_train.append(label)\n","\n","X_train = np.array(X_train)\n","y_train = np.array(y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aV9bFtrCIbvB"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FOZUvyuwJ_z4"},"outputs":[],"source":["# Hyper-parameters \n","num_epochs = 1000\n","batch_size = 8\n","learning_rate = 0.001\n","input_size = len(X_train[0])\n","hidden_size = 8\n","output_size = len(tags)\n","print(input_size, output_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XnmOZep1JkED"},"outputs":[],"source":["class ChatDataset(Dataset):\n","\n","    def __init__(self):\n","        self.n_samples = len(X_train)\n","        self.x_data = X_train\n","        self.y_data = y_train\n","\n","    # support indexing such that dataset[i] can be used to get i-th sample\n","    def __getitem__(self, index):\n","        return self.x_data[index], self.y_data[index]\n","\n","    # we can call len(dataset) to return the size\n","    def __len__(self):\n","        return self.n_samples\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lI4ekF8GJrJe"},"outputs":[],"source":["dataset = ChatDataset()\n","train_loader = DataLoader(dataset=dataset,\n","                          batch_size=batch_size,\n","                          shuffle=True,\n","                          num_workers=0)"]},{"cell_type":"markdown","metadata":{"id":"avZ4mrOxL2h1"},"source":["MODEL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f97ztg_9L1-Y"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","\n","class NeuralNet(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(NeuralNet, self).__init__()\n","        self.l1 = nn.Linear(input_size, hidden_size) \n","        self.l2 = nn.Linear(hidden_size, hidden_size) \n","        self.l3 = nn.Linear(hidden_size, num_classes)\n","        self.relu = nn.ReLU()\n","    \n","    def forward(self, x):\n","        out = self.l1(x)\n","        out = self.relu(out)\n","        out = self.l2(out)\n","        out = self.relu(out)\n","        out = self.l3(out)\n","        # no activation and no softmax at the end\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lqZVDnCgJ2nM"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = NeuralNet(input_size, hidden_size, output_size).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YYCXcH3VNJhe"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()           # Loss and optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"markdown","metadata":{"id":"KjkbVRVcNXxX"},"source":["TRAINING DATA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NdFijVbZNStV"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [100/1000], Loss: 0.9038\n","Epoch [200/1000], Loss: 0.3577\n","Epoch [300/1000], Loss: 0.0486\n","Epoch [400/1000], Loss: 0.0386\n","Epoch [500/1000], Loss: 0.0072\n","Epoch [600/1000], Loss: 0.0066\n","Epoch [700/1000], Loss: 0.0053\n","Epoch [800/1000], Loss: 0.0009\n","Epoch [900/1000], Loss: 0.0019\n","Epoch [1000/1000], Loss: 0.0003\n","final loss: 0.0003\n"]}],"source":["# Train the model\n","for epoch in range(num_epochs):\n","    for (words, labels) in train_loader:\n","        words = words.to(device)\n","        labels = labels.to(dtype=torch.long).to(device)\n","        \n","        # Forward pass\n","        outputs = model(words)\n","        # if y would be one-hot, we must apply\n","        # labels = torch.max(labels, 1)[1]\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","    if (epoch+1) % 100 == 0:\n","        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","\n","print(f'final loss: {loss.item():.4f}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"X_qvHN0Ke4_6"},"outputs":[{"name":"stdout","output_type":"stream","text":["training complete. file saved to data.pth\n"]}],"source":["data = {\n","\"model_state\": model.state_dict(),\n","\"input_size\": input_size,\n","\"hidden_size\": hidden_size,\n","\"output_size\": output_size,\n","\"all_words\": all_words,\n","\"tags\": tags\n","}\n","\n","FILE = \"data.pth\"\n","torch.save(data, FILE)\n","\n","print(f'training complete. file saved to {FILE}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Rkj5vQBjgOlH"},"outputs":[],"source":["data = torch.load(FILE)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Wia5lwACgTuR"},"outputs":[],"source":["input_size = data[\"input_size\"]\n","hidden_size = data[\"hidden_size\"]\n","output_size = data[\"output_size\"]\n","all_words = data['all_words']\n","tags = data['tags']\n","model_state = data[\"model_state\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"aOdtPT78gXdF"},"outputs":[{"data":{"text/plain":["NeuralNet(\n","  (l1): Linear(in_features=54, out_features=8, bias=True)\n","  (l2): Linear(in_features=8, out_features=8, bias=True)\n","  (l3): Linear(in_features=8, out_features=7, bias=True)\n","  (relu): ReLU()\n",")"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["model = NeuralNet(input_size, hidden_size, output_size).to(device)\n","model.load_state_dict(model_state)\n","model.eval()   #evaluation mode"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HIw3_F-1ggQd"},"outputs":[],"source":["bot_name = \"XYZ\""]},{"cell_type":"code","execution_count":191,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":982607,"status":"ok","timestamp":1617621123900,"user":{"displayName":"Pulkit Bhagat","photoUrl":"https://lh5.googleusercontent.com/-4JCNF-pRcJY/AAAAAAAAAAI/AAAAAAAABV8/rUWo1zHWTtM/s64/photo.jpg","userId":"06821213227967213188"},"user_tz":-330},"id":"PQkF1bRignbr","outputId":"61d79d11-b724-488a-bbfd-c52358de0c43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Let's chat! (type 'quit' to exit)\n","You: hi\n","XYZ: Hey :-)\n","You: what do you sell?\n","XYZ: We sell coffee and tea\n","You: umm wanna go out?\n","XYZ: I do not understand...\n","You: bye\n","XYZ: Have a nice day\n","You: quit\n"]}],"source":["import random\n","\n","print(\"Let's chat! (type 'quit' to exit)\")\n","\n","while True:\n","    # sentence = \"do you use credit cards?\"\n","    sentence = input(\"You: \")\n","    if sentence == \"quit\":\n","        break\n","\n","    sentence = tokenize(sentence)\n","    X = bag_of_words(sentence, all_words)\n","    X = X.reshape(1, X.shape[0])\n","    X = torch.from_numpy(X).to(device)\n","\n","    output = model(X)\n","    _, predicted = torch.max(output, dim=1)\n","\n","    tag = tags[predicted.item()]\n","\n","    probs = torch.softmax(output, dim=1)\n","    prob = probs[0][predicted.item()]\n","    if prob.item() \u003e 0.75:\n","        for intent in intents['intents']:\n","            if tag == intent[\"tag\"]:\n","                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n","    else:\n","        print(f\"{bot_name}: I do not understand...\")\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMZHMAM0I8/akvjhTRNxk24","name":"chatbox.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}